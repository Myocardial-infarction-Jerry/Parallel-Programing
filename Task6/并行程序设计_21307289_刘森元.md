# Parallel-Programming Task6

<center><div style='height:2mm;'></div><div style="font-family:华文楷体;font-size:14pt;">刘森元, 21307289</div></center>
<center><span style="font-family:华文楷体;font-size:9pt;line-height:9mm">中山大学计算机学院</span>
</center>

Codes on https://github.com/Myocardial-infarction-Jerry/Parallel-Programming/tree/main/Task6.

Project built by CMake.

```shell
> cd Task6
> cmake . && make
> ./MatMul
```

## Environment

Apple M1 Pro

macOS Sonoma 14.4.1

## Task

### 构造基于 Pthreads 的并行 for 循环分解、分配、执行机制

> [!NOTE]
>
> 模仿 OpenMP 的 `omp_parallel_for` 构造基于 Pthreads 的并行 for 循环分解、分配及执行机制。次内容延续上次实验，在本次试验中完成。
>
> ***问题描述：***生成一个包含 `parallel_for` 函数的动态链接库（.so）文件，该函数创建多个 Pthreads 线程，并行执行 `parallel_for` 函数的参数所指定的内容。
>
> ***函数参数：***`parallel_for` 函数的参数应当指明被并行循环的索引信息，循环中所需要执行的内容，并行构造等。以下为 `parallel_for` 函数的基础定义，实验实现应包括但不限于以下内容：
>
> ```cpp
> void parallel_for(int start, 
>                   int end, 
>                   int inc, 
>                   void *(*functor)(int, void *), 
>                   void *arg,int num_threads);
> ```
>
> - `start, end, inc` 分别为循环的开始、结束以及索引自增量；
> - `functor` 为函数指针，定义了每次循环所执行的内容；
> - `arg` 为 `functor` 的参数指针，给出了 `functor` 执行所需的数据；
> - `num_threads` 为期望产生的线程数量。
>
> ***要求：***完成 `parallel_for` 函数实现并生成动态链接库文件，并以矩阵乘法为例，测试其实现的正确性及效率。

### parallel_for 并行应用

> [!NOTE]
>
> 使用此前构造的 `parallel_for` 并行结构，将 `heated_plate_openmp` 改造为基于 Pthreads 的并行应用。
>
> ***heated plate 问题描述：***规则网格上的热传导模拟，其具体过程为每次循环中通过对邻域内热量平均模拟热传导过程，即：
> $$
> w_{i,j}^{t+1}=\frac14(w_{i-1,j-1}^t+w^t_{i-1,j+1}+w^t_{i+1,j-1}+w^t_{i+1,j+1})
> $$
> ***要求：***使用此前构造的 `parallel_for` 并行结构，将 `heated_plate_openmp` 实现改造为基于 Pthreads 的并行应用。测试不同线程、调度方式下的程序并行性能，并于原始 `heated_plate_openmp.c` 实现对比。

## Theory

1. 在多线程环境中加速执行任务，将一组独立的循环迭代分配给不同的线程，减少整体执行时间。
2. **任务分配：**
   - 将循环迭代范围划分成多个小任务，每个线程负责执行其中的一部分。
   - 各个线程的起始迭代值由线程索引决定，每个线程以固定的增量执行循环。
3. **增量计算：**
   - 根据线程数和循环增量，计算每个线程的迭代增量，使得线程之间没有重叠或遗漏。
   - 线程的起始点：`起始 + 线程索引 * 增量`
   - 线程的步长：`线程数 * 增量`
4. **线程执行：**
   - 每个线程独立执行其任务区间，避免线程间的资源竞争。
   - 使用同步原语（如 `join`）等待所有线程完成。
5. **任务执行函数：**
   - 用户自定义工作函数（“任务执行函数”）接受迭代索引和附加参数。
   - 每个线程调用任务执行函数来完成其分配的循环迭代。
6. **负载均衡：**
   - 通过均匀分配循环迭代次数，保证所有线程的工作量大致均衡。

## Code

### OpenMP 通用矩阵乘法

> [!CAUTION]
>
> 源代码详见 [OpenMPMatMul.cpp](https://github.com/Myocardial-infarction-Jerry/Parallel-Programming/blob/main/Task5/OpenMPMatMul.cpp)



## Result

### OpenMP 通用矩阵乘法

以 8 核心 512 矩阵默认调度模式下为例

![image-20240423151802386](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20240423151802386.png)

其中 `matMul time` 为并行矩阵乘法运行时间.

| 进程数量/矩阵规模 (s) | 128      | 256      | 512      | 1024     | 2048      |
| --------------------- | -------- | -------- | -------- | -------- | --------- |
| 1                     | 0.014097 | 0.070119 | 0.543809 | 4.048968 | 82.492855 |
| 2                     | 0.017437 | 0.091779 | 0.627493 | 3.168582 | 48.964278 |
| 4                     | 0.020966 | 0.111330 | 0.547351 | 3.426131 | 27.645359 |
| 8                     | 0.038651 | 0.156202 | 0.697604 | 3.350200 | 33.643892 |
| 16                    | 0.054763 | 0.279289 | 5.988570 | 6.243032 | 41.413419 |

![pics](/Users/qiu_nangong/Documents/GitHub/Parallel-Programming/Task5/pics.png)

- 随着进程数量的增加, 程序的运行时间在大多数情况下都有所减少. 
- 当进程数量增加到 16 时, 对于规模为 2048 的矩阵, 运行时间并没有显著减少. 这是因为进程间的通信开销开始超过了并行计算带来的收益, 即 Amdahl 定律. 
- 随着矩阵规模的增加, 程序的运行时间也在增加. 矩阵乘法的计算复杂度为 $O(n^3)$, 所以当矩阵规模增加时, 所需的计算量也会显著增加. 
- 程序在多进程下表现出了良好的性能提升, 但当进程数量增加到一定程度后, 通信开销可能会开始影响性能. 
- 代码的扩展性受限于线程数量, 当线程数量有限时, 并行化带来的收益并不显著.

以 8 核心 2048 矩阵为例，`chunk_size = 16`，不同调度模式下时间对比

| 默认      | 静态      | 动态      |
| --------- | --------- | --------- |
| 31.196983 | 22.504740 | 67.854195 |

- ***默认调度模式：***在默认调度模式下，OpenMP 运行时环境决定如何分配迭代。这可能导致负载不均衡，尤其是在迭代的计算成本不均匀的情况下。这可能是默认调度模式下时间较长的原因。
- ***静态调度模式：***在静态调度模式下，迭代被均匀地分配给各个线程。如果所有迭代的计算成本都大致相同，那么这种调度模式通常能提供最好的性能，因为它可以最大限度地减少线程之间的同步开销。这可能是静态调度模式下时间较短的原因。
- ***动态调度模式：***在动态调度模式下，迭代被动态地分配给各个线程。这种调度模式适用于迭代的计算成本不均匀的情况，因为它可以在运行时动态地平衡负载。然而，动态调度模式的开销通常比静态调度模式要大，因为它需要在运行时进行更多的同步和调度操作。这可能是动态调度模式下时间较长的原因。
